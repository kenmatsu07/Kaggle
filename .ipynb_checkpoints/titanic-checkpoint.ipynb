{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "print (sklearn.__version__)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import  SVC\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ名\n",
    "input_dir = ur\"C:/Users/mirait/wk/git/input/\"\n",
    "output_dir = ur\"C:/Users/mirait/wk/git/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データを読み込む\n",
    "train_path = input_dir + ur\"train.csv\"\n",
    "train_data = pd.read_csv(train_path, encoding=\"cp932\",low_memory=False)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータを読み込む\n",
    "test_path = input_dir + ur\"test.csv\"\n",
    "test_data = pd.read_csv(test_path, encoding=\"cp932\",low_memory=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ：レコード長 891\n",
      "訓練データ：カラム数 12\n",
      "テストデータ：レコード長 418\n",
      "テストデータ：カラム数 11\n"
     ]
    }
   ],
   "source": [
    "print \"訓練データ：レコード長\", len(train_data)\n",
    "print \"訓練データ：カラム数\",len(train_data.columns)\n",
    "print \"テストデータ：レコード長\", len(test_data)\n",
    "print \"テストデータ：カラム数\",len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析に生かすために項目の特徴量を取得\n",
    "def feature(df):\n",
    "    \n",
    "    df_feature = pd.DataFrame()\n",
    "    \n",
    "    for i in (range(len(df.columns))):\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp = df.iloc[:, [i]]\n",
    "        \n",
    "        selList = list()\n",
    "        record_cn = len(tmp) #レコード数\n",
    "        column_name = tmp.columns[0] #カラム名\n",
    "        value_type_cn = len(pd.value_counts(tmp.values.flatten())) #値の種類数(NAはカウント外)\n",
    "        NA_cn = tmp.isnull().sum().values[0] #NA件数\n",
    "\n",
    "        feature_list = list([record_cn, column_name, value_type_cn, NA_cn])\n",
    "        now_column = pd.DataFrame(feature_list).T\n",
    "        #print res1\n",
    "        \n",
    "        df_feature = pd.concat([df_feature, now_column], ignore_index=True)\n",
    "    \n",
    "    df_feature.columns = [u'レコード数', u'カラム名', 'v_count', u'NA件数']\n",
    "        \n",
    "    col_names = list(df_feature.columns)\n",
    "    df_feature = df_feature.loc[:, col_names]\n",
    "\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 訓練データの特徴量\n",
    "feature_train = feature(train_data)\n",
    "print len(feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# テストデータの特徴量\n",
    "feature_test = feature(test_data)\n",
    "print len(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_train = os.path.join(output_dir, \"column_feature_train.csv\")\n",
    "feature_train.to_csv(output_feature_train, encoding=\"cp932\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_test = os.path.join(output_dir, \"column_feature_test.csv\")\n",
    "feature_test.to_csv(output_feature_test, encoding=\"cp932\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ型が定義されているファイルを読み込み　（データ型は独自判断）\n",
    "type_list = input_dir + ur\"type_list.csv\"\n",
    "df_type = pd.read_csv(type_list, encoding=\"cp932\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survived</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fare</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    column_name    type\n",
       "0   PassengerId    char\n",
       "1      Survived    char\n",
       "2        Pclass    char\n",
       "3          Name    char\n",
       "4           Sex    char\n",
       "5           Age  number\n",
       "6         SibSp  number\n",
       "7         Parch  number\n",
       "8        Ticket    char\n",
       "9          Fare  number\n",
       "10        Cabin    char\n",
       "11     Embarked    char"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_char = df_type.query('type == \"char\"')\n",
    "char_type_column = set(list(type_char[\"column_name\"]))\n",
    "train_char = train_data.loc[:, char_type_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 値の種類数が100以上の項目は除外対象とする　（カテゴリ項目のみ）\n",
    "over_value100_list = list(feature_train.query(\"v_count >= 100\")[u\"カラム名\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ項目を抽出し除外\n",
    "char_column = list(train_char.columns)\n",
    "del_char = list(set(char_column) & set(over_value100_list))\n",
    "wk_set = set(list(train_data.columns)) - set(del_char)\n",
    "wk_sel = list(wk_set)\n",
    "clean_train = train_data.loc[:, wk_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fare Embarked   Age  Parch  Pclass     Sex  Survived  SibSp\n",
      "0   7.2500        S  22.0      0       3    male         0      1\n",
      "1  71.2833        C  38.0      0       1  female         1      1\n",
      "2   7.9250        S  26.0      0       3  female         1      0\n",
      "3  53.1000        S  35.0      0       1  female         1      1\n",
      "4   8.0500        S  35.0      0       3    male         0      0\n",
      "Index([u'Fare', u'Embarked', u'Age', u'Parch', u'Pclass', u'Sex', u'Survived',\n",
      "       u'SibSp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print clean_train.head()\n",
    "print clean_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字列（Embarked）の最頻値を抽出するのは実装上困難なため、replaceで代替\n",
    "pd.value_counts(clean_train[\"Embarked\"]) # \"S\"\n",
    "clean_train[\"Embarked\"] = clean_train[\"Embarked\"].replace([np.nan],\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値が存在する項目（Age）は平均値で置換\n",
    "clean_train[\"Age\"] = clean_train[\"Age\"].fillna(clean_train[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fare        False\n",
      "Embarked    False\n",
      "Age         False\n",
      "Parch       False\n",
      "Pclass      False\n",
      "Sex         False\n",
      "Survived    False\n",
      "SibSp       False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 欠損値が存在しないことを確認\n",
    "print clean_train.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数\"Survived\"がダミー変数化対象になるため退避\n",
    "target = clean_train[\"Survived\"]\n",
    "clean_train_wk = clean_train.drop(columns = {\"Survived\"},axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "値0 549\n",
      "値1 342\n"
     ]
    }
   ],
   "source": [
    "# 目的変数の値を確認\n",
    "print \"値0\", len(clean_train.query('Survived == 0'))\n",
    "print \"値1\", len(clean_train.query('Survived == 1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力ファイルの項目数　：　CHAR型の項目数　： 7 ： 3\n"
     ]
    }
   ],
   "source": [
    "# カテゴリ項目を抽出\n",
    "clean_train_column = set(list(clean_train_wk.columns))\n",
    "char_column = set(list(type_char[\"column_name\"]))\n",
    "char_match_lis2 = list(clean_train_column & char_column)\n",
    "print \"入力ファイルの項目数　：　CHAR型の項目数　：\", len(clean_train_wk.columns), \"：\", len(char_match_lis2)\n",
    "char_column_lis2 = clean_train_wk.loc[:,char_match_lis2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値項目を抽出\n",
    "type_num = df_type.query('type == \"number\"')\n",
    "num_type_column = set(list(type_num[\"column_name\"]))\n",
    "train_num = clean_train_wk.loc[:, num_type_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_ex = char_column_lis2.astype('unicode')\n",
    "# フラグ値ではないため先頭値は削除しない\n",
    "char_ex_dum = pd.get_dummies(char_ex, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数を結合 (分割前に同じdfになければ、indexがずれるのでマージ前に結合しておく)\n",
    "wk = pd.concat([char_ex_dum,target], axis=1)\n",
    "# マージ\n",
    "merge_file = pd.concat([train_num,wk], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "13\n",
      "      Fare   Age  SibSp  Parch  Sex_female  Sex_male  Pclass_1  Pclass_2  \\\n",
      "0   7.2500  22.0      1      0           0         1         0         0   \n",
      "1  71.2833  38.0      1      0           1         0         1         0   \n",
      "2   7.9250  26.0      0      0           1         0         0         0   \n",
      "3  53.1000  35.0      1      0           1         0         1         0   \n",
      "4   8.0500  35.0      0      0           0         1         0         0   \n",
      "\n",
      "   Pclass_3  Embarked_C  Embarked_Q  Embarked_S  Survived  \n",
      "0         1           0           0           1         0  \n",
      "1         0           1           0           0         1  \n",
      "2         1           0           0           1         1  \n",
      "3         0           0           0           1         1  \n",
      "4         1           0           0           1         0  \n"
     ]
    }
   ],
   "source": [
    "print len(merge_file)\n",
    "print len(merge_file.columns)\n",
    "print merge_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "891 :NA行数  0\n",
      "891 :inf行数  0\n"
     ]
    }
   ],
   "source": [
    "# 欠損値の処理\n",
    "tmp01 = merge_file.copy()\n",
    "print len(tmp01)\n",
    "tmp02 = tmp01.dropna()\n",
    "print len(tmp02),\":NA行数 \",(len(tmp01)-len(tmp02))\n",
    "tmp03 = tmp02.replace([np.inf,-np.inf],np.nan)    #infの置換\n",
    "tmp04 = tmp03.dropna().reset_index(drop =True)\n",
    "print len(tmp04),\":inf行数 \",(len(tmp03)-len(tmp04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "891\n"
     ]
    }
   ],
   "source": [
    "# 説明変数、目的変数への分割\n",
    "X = tmp04.drop(columns = {u\"Survived\"},axis =1)\n",
    "y = tmp04.loc[:,[u\"Survived\"]]\n",
    "\n",
    "print len(X.columns)\n",
    "print len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ分割\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値項目の標準化のため、カラム単位でデータ型を分離\n",
    "X_column = list(X.columns)\n",
    "num_column = set(list(train_num.columns))\n",
    "char_column = set(X_column) - set(num_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値項目において訓練データの平均値/標準偏差から訓練データ、テストデータのz-scoreを算出し標準化する\n",
    "# StandardScalerは上記が実現不可のため個別実装\n",
    "def number_scaler(X_train, X_test):\n",
    "    \n",
    "    train_scaler = pd.DataFrame()\n",
    "    test_scaler = pd.DataFrame()\n",
    "    train_std = pd.DataFrame()\n",
    "    \n",
    "    train_num = X_train.loc[:, num_column]\n",
    "    test_num = X_test.loc[:, num_column]\n",
    "    \n",
    "    # 標準化後にカテゴリ項目をマージさせるために定義\n",
    "    train_char = X_train.loc[:, char_column]\n",
    "    test_char = X_test.loc[:, char_column]\n",
    "    \n",
    "    # 標準偏差を詰めるリスト\n",
    "    std_lis =[]\n",
    "    \n",
    "    # 訓練データの平均値、標準偏差を取得\n",
    "    for i in train_num.columns:        \n",
    "        train_mean = train_num[i].mean()\n",
    "        train_std = train_num[i].std()\n",
    "        \n",
    "        # z-scoreを求める\n",
    "        train_z = pd.DataFrame({i:(train_num[i] - train_mean) / train_std})\n",
    "        test_z = pd.DataFrame({i:(test_num[i] - train_mean) / train_std})\n",
    "        # 訓練データの標準偏差を詰める\n",
    "        std_lis.append(train_std) \n",
    "        \n",
    "        train_scaler = pd.concat([train_scaler, train_z], axis=1)\n",
    "        test_scaler = pd.concat([test_scaler, test_z], axis=1)\n",
    "    \n",
    "    # カテゴリ項目をマージ\n",
    "    train_scaler = pd.concat([train_scaler,train_char], axis=1)\n",
    "    test_scaler = pd.concat([test_scaler,test_char], axis=1)\n",
    "    \n",
    "    # 訓練データの分割次第では標準偏差が0となり、z-scoreが'Nan'となるため0埋めする\n",
    "    train_scaler = train_scaler.fillna(0)\n",
    "    test_scaler = test_scaler.fillna(0)\n",
    "    \n",
    "    # 項目の標準偏差を出力\n",
    "    train_std = pd.DataFrame(std_lis).T\n",
    "    train_std.columns = num_column\n",
    "    train_std= train_std.T.reset_index(drop=False)\n",
    "    train_std.columns =[\"col_name\",\"std\"]\n",
    "    \n",
    "    print \"train:\",len(train_scaler)\n",
    "    print \"test:\",len(test_scaler)\n",
    "\n",
    "    return train_scaler, test_scaler, train_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ\n",
    "def grid_sgd(X, y, sc_list, grid_param, cv):\n",
    "    \n",
    "    # SGD\n",
    "    clf = linear_model.SGDClassifier(loss='log', penalty='elasticnet', random_state=0, class_weight='balanced',max_iter=50)\n",
    "    # パラメータ探索\n",
    "    score = sc_list[0]\n",
    "    gs = GridSearchCV(clf, grid_param, cv=cv, scoring=score)\n",
    "    gs.fit(X_train,y_train)\n",
    "    \n",
    "    # グリッドサーチの結果を出力\n",
    "    result = pd.DataFrame(gs.grid_scores_)\n",
    "    result = result.rename(columns={'mean_validation_score':score})\n",
    "    result = result.iloc[:,[0,1]]\n",
    "    print gs.best_params_\n",
    "    \n",
    "    for i in sc_list[1:]:\n",
    "        score = i\n",
    "        gs = GridSearchCV(clf, grid_param, cv=cv, scoring=score)\n",
    "        gs.fit(X_train,y_train)\n",
    "        res = pd.DataFrame(gs.grid_scores_)\n",
    "        res = res.rename(columns={'mean_validation_score':score})\n",
    "        res = res.iloc[:,[1]]\n",
    "        result = pd.concat([result,res],axis=1)\n",
    "    \n",
    "    return result, gs.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 引数としたrecall値の閾値を取得\n",
    "def get_recall_value(X_test_scaler, y_test, clf ,recall_n):\n",
    "    \n",
    "    # 任意の閾値のprecision、recallを取得\n",
    "    prob = clf.predict_proba(X_test_scaler)[:,1]\n",
    "    fpr,tpr,thresholds = roc_curve(y_test, prob)\n",
    "\n",
    "    fpr_df = pd.DataFrame(fpr)\n",
    "    tpr_df = pd.DataFrame(tpr)\n",
    "    there_df = pd.DataFrame(thresholds)\n",
    "    df_roc = pd.concat([fpr_df, tpr_df, there_df], axis=1)\n",
    "    df_roc.columns = [\"fpr\",\"tpr\",\"thresholds\"]\n",
    "    \n",
    "    over_recall = (df_roc.query('tpr >= @recall_n ')).reset_index(drop=True)\n",
    "    print len(over_recall)\n",
    "\n",
    "    # 閾値を取得\n",
    "    thresholds_n = round((over_recall[\"thresholds\"][0]),3)\n",
    "    \n",
    "    print thresholds_n\n",
    "    return thresholds_n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# モデル評価\n",
    "def score_result(X_test_scaler, y_test, clf, col_name, thresholds_n, recall_n):\n",
    "    \n",
    "    # recall固定値\n",
    "    fix_recall = str(recall_n * 100)+\"%\"\n",
    "    \n",
    "    y_prob = (clf.predict_proba(X_test_scaler)[:,1] >= thresholds_n).astype(int)\n",
    "    \n",
    "    # 閾値のモデル精度\n",
    "    ac_score = round((accuracy_score(y_test, y_prob)), 3)\n",
    "    pre_score = round((precision_score(y_test, y_prob)), 3)\n",
    "    rec_score = round((recall_score(y_test, y_prob)), 3)\n",
    "    f1_s = round((f1_score(y_test, y_prob)), 3)\n",
    "    \n",
    "    # predict_probaでaucを算出\n",
    "    prob = clf.predict_proba(X_test_scaler)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,prob)\n",
    "    auc_score = round(auc(fpr,tpr),3)\n",
    "    \n",
    "    tmp = [fix_recall, auc_score, ac_score, pre_score, rec_score, f1_s]\n",
    "    score_df = pd.DataFrame(tmp)\n",
    "    score_df.index = [\"fix_Recall\", \"AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_score\"]\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD (回帰係数、precision評価版)\n",
    "def sgd(X_train, y_train, X_test, y_test, param, X_std):\n",
    "    \n",
    "    # モデル構築\n",
    "    clf =linear_model.SGDClassifier(loss='log', penalty='elasticnet', random_state=0, class_weight='balanced',\n",
    "                                    alpha = param['alpha'] , l1_ratio = param['l1_ratio'], max_iter=500)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # モデル評価を出力\n",
    "    print \"score:\", clf.score(X_test,y_test)\n",
    "    print \"confusion_matrix:\"\n",
    "    print confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "    # 回帰係数を出力\n",
    "    coeff_df = pd.DataFrame([X_train.columns,  clf.coef_[0]]).T\n",
    "    coeff_df.columns = [\"col_name\",\"coef\"] \n",
    "    coeff_df[\"coef_abs\"] = abs(coeff_df[\"coef\"] )\n",
    "    coeff_sort = coeff_df.sort_values(by=\"coef_abs\", ascending=False).reset_index(drop=True)\n",
    "    # 回帰係数+標準偏差でマージ\n",
    "    coeff_merge = pd.merge(coeff_sort, X_std, on=\"col_name\", how=\"left\")\n",
    "    coeff_merge[\"coef/std\"] = coeff_merge[\"coef\"]/coeff_merge[\"std\"]\n",
    "    \n",
    "    for i in range(len(coeff_merge)):\n",
    "        if np.isnan(coeff_merge.loc[i,\"coef/std\"]) == True:\n",
    "            coeff_merge.loc[i,\"coef/std\"] = coeff_merge.loc[i,\"coef\"]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "#     print \"\"\n",
    "#     print \"回帰係数の総数\",len(coeff_sort)\n",
    "    coeff_sort.coef =coeff_sort.coef.astype(np.float)\n",
    "#     print \"回帰係数 0の数\",len(coeff_sort.query('coef == 0'))\n",
    "#     print \"回帰係数 0以外の数\",len(coeff_sort.query('coef != 0'))\n",
    "    \n",
    "\n",
    "    # 適合率、再現率、閾値をそれぞれ出力\n",
    "    print \"\"\n",
    "    precision, recall, threshold = precision_recall_curve(y_test, clf.predict_proba(X_test)[:,1] )#\n",
    "\n",
    "#     print \"precision \",precision\n",
    "#     print \"recall_\",recall\n",
    "#     print \"threshold\",threshold\n",
    "    \n",
    "    print \"\"\n",
    "    print (sklearn.metrics.classification_report(y_test, clf.predict(X_test)))\n",
    "    \n",
    "    print \"\"\n",
    "    prob = clf.predict_proba(X_test)[:,1]\n",
    "    fpr,tpr,thresholds = sklearn.metrics.roc_curve(y_test,prob)\n",
    "    print \"auc\", round(sklearn.metrics.auc(fpr,tpr),4)\n",
    "    \n",
    "    # ROC曲線\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel(\"False Positve Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    #plt.show()\n",
    "    \n",
    "    return clf, coeff_sort, coeff_merge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# SGD (エラスティックネット) (recall評価版)\n",
    "def sgd(X_train_scaler, X_test_scaler, y_train, y_test, recall_50, recall_90):\n",
    "    \n",
    "    clf =linear_model.SGDClassifier(loss='log', penalty='elasticnet', random_state=0, class_weight='balanced',\n",
    "                                    alpha=grid_sgd_param[u'alpha'] , l1_ratio=grid_sgd_param[u'l1_ratio'], max_iter=500)\n",
    "    clf.fit(X_train_scaler,y_train)\n",
    "    \n",
    "    # 項目毎の回帰係数を出力\n",
    "    coeff_df = pd.DataFrame([X_train_scaler.columns, clf.coef_[0]]).T\n",
    "    coeff_df.columns = [\"col_name\",\"coef\"] \n",
    "    coeff_df[\"coef_abs\"] = abs(coeff_df[\"coef\"] )\n",
    "    coeff_df_sort = coeff_df.sort_values(by=\"coef_abs\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print \"回帰係数の総数\",len(coeff_df_sort)\n",
    "    coeff_df_sort.coef =coeff_df_sort.coef.astype(np.float)\n",
    "    print \"回帰係数 0の数\",len(coeff_df_sort.query('coef == 0'))\n",
    "    print \"回帰係数 0以外の数\",len(coeff_df_sort.query('coef != 0'))\n",
    "    \n",
    "    col_name = \"SGDClassifier\"\n",
    "    \n",
    "    # recall:50%の評価\n",
    "    thre_50 = get_recall_value(X_test_scaler, y_test, clf, recall_50)#probの指定\n",
    "    print \"recall:\",recall_50,\" -> 閾値\",thre_50\n",
    "    score_recall_50 = score_result(X_test_scaler, y_test, clf, col_name, thre_50, recall_50)\n",
    "    \n",
    "    # recall:90%の評価\n",
    "    thre_90 = get_recall_value(X_test_scaler, y_test, clf, recall_90)\n",
    "    print \"recall:\",recall_90,\" -> 閾値\",thre_90\n",
    "    score_recall_90 = score_result(X_test_scaler, y_test, clf, col_name, thre_90, recall_90)    \n",
    "    \n",
    "    # AUC値を取得\n",
    "    prob = clf.predict_proba(X_test_scaler)[:,1]\n",
    "    fpr,tpr,thresholds = sklearn.metrics.roc_curve(y_test,prob)\n",
    "    print \"auc\", round(sklearn.metrics.auc(fpr,tpr),4)\n",
    "    \n",
    "    # ROC曲線を出力\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel(\"False Positve Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    \n",
    "    return coeff_df_sort, score_recall_50, score_recall_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 623\n",
      "test: 268\n"
     ]
    }
   ],
   "source": [
    "# 数値項目を標準化\n",
    "X_train_scaler, X_test_scaler, X_train_std = number_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの欠損値を削除した上で目的変数に欠損値が存在しない行を指定する\n",
    "X_test_scaler = (X_test_scaler.replace([np.inf,-np.inf],np.nan)).dropna()\n",
    "noinf_ix = list(X_test_scaler.index)\n",
    "y_test = y_test.loc[noinf_ix,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Fare', u'Age', u'SibSp', u'Parch', u'Pclass_1', u'Embarked_Q',\n",
      "       u'Pclass_3', u'Pclass_2', u'Sex_male', u'Sex_female', u'Embarked_S',\n",
      "       u'Embarked_C'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print X_train_scaler.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価値\n",
    "#sc_list = ['roc_auc','accuracy','f1']\n",
    "sc_list = ['accuracy']\n",
    "# 交差検定の実行回数\n",
    "cv  = 10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1回目：{'alpha': [0.1, 0.01, 0.001],'l1_ratio': [0, 0.05, 0.1, 0.15]}\n",
    "{'alpha': 0.01, 'l1_ratio': 0.05}\n",
    "\n",
    "2回目：{'alpha': [0.006, 0.01, 0.05],'l1_ratio': [0.03, 0.05, 0.07]}\n",
    "{'alpha': 0.01, 'l1_ratio': 0.07}\n",
    "\n",
    "3回目：{'alpha': [0.009, 0.01, 0.03],'l1_ratio': [0.07, 0.08, 0.09]}\n",
    "{'alpha': 0.009, 'l1_ratio': 0.07}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDパラメータリスト\n",
    "param = [{'alpha': [0.009, 0.01, 0.03],'l1_ratio': [0.07, 0.08, 0.09]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirait\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.009, 'l1_ratio': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirait\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_result_SGD, best_param_SGD = grid_sgd(X_train_scaler, y_train, sc_list, param, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチの探索結果を出力\n",
    "output_grid = os.path.join(output_dir, \"grid_SGD.csv\")\n",
    "grid_result_SGD.to_csv(output_grid, encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7835820895522388\n",
      "confusion_matrix:\n",
      "[[134  34]\n",
      " [ 24  76]]\n",
      "\n",
      "precision  [0.3875969  0.38521401 0.3828125  0.38431373 0.38582677 0.38735178\n",
      " 0.38888889 0.38645418 0.388      0.38955823 0.39112903 0.39271255\n",
      " 0.39430894 0.39591837 0.39754098 0.39506173 0.39669421 0.39834025\n",
      " 0.4        0.39748954 0.39915966 0.40084388 0.40254237 0.40425532\n",
      " 0.40598291 0.40772532 0.40948276 0.41125541 0.41304348 0.41484716\n",
      " 0.42410714 0.43378995 0.43577982 0.43778802 0.43981481 0.44392523\n",
      " 0.44600939 0.44339623 0.44549763 0.44761905 0.44497608 0.44711538\n",
      " 0.44444444 0.44660194 0.44878049 0.45098039 0.44827586 0.45049505\n",
      " 0.45273632 0.455      0.45728643 0.45959596 0.46192893 0.46428571\n",
      " 0.46666667 0.46907216 0.47150259 0.47395833 0.47643979 0.47894737\n",
      " 0.48148148 0.48404255 0.48924731 0.48648649 0.48913043 0.49450549\n",
      " 0.49723757 0.5        0.5027933  0.50561798 0.50847458 0.51136364\n",
      " 0.52023121 0.52046784 0.51764706 0.52071006 0.52694611 0.53012048\n",
      " 0.53333333 0.53658537 0.5398773  0.54320988 0.54658385 0.54375\n",
      " 0.54716981 0.55063291 0.55414013 0.55769231 0.56129032 0.56493506\n",
      " 0.56862745 0.57236842 0.57615894 0.57333333 0.5704698  0.56756757\n",
      " 0.57142857 0.57534247 0.57931034 0.58333333 0.58741259 0.6\n",
      " 0.60431655 0.60869565 0.61313869 0.61764706 0.62222222 0.62686567\n",
      " 0.63157895 0.63636364 0.64122137 0.64615385 0.65116279 0.65625\n",
      " 0.66141732 0.66666667 0.672      0.67741935 0.67479675 0.67213115\n",
      " 0.67768595 0.68333333 0.68067227 0.68644068 0.68376068 0.68103448\n",
      " 0.67826087 0.68421053 0.69026549 0.69642857 0.69369369 0.69090909\n",
      " 0.69724771 0.7037037  0.71028037 0.70754717 0.7047619  0.71153846\n",
      " 0.70873786 0.71568627 0.72277228 0.73       0.72727273 0.73469388\n",
      " 0.74226804 0.75       0.74736842 0.75531915 0.76344086 0.76086957\n",
      " 0.75824176 0.76666667 0.7752809  0.78409091 0.79310345 0.80232558\n",
      " 0.8        0.79761905 0.79518072 0.79268293 0.80246914 0.8\n",
      " 0.79746835 0.80769231 0.81818182 0.81578947 0.82666667 0.82432432\n",
      " 0.82191781 0.83333333 0.84507042 0.84285714 0.85507246 0.85294118\n",
      " 0.85074627 0.86363636 0.87692308 0.875      0.88888889 0.88709677\n",
      " 0.9        0.89830508 0.9137931  0.9122807  0.91071429 0.90909091\n",
      " 0.90740741 0.90566038 0.90384615 0.92156863 0.92       0.93877551\n",
      " 0.9375     0.93617021 0.93478261 0.93333333 0.95454545 0.97674419\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.        ]\n",
      "recall_ [1.   0.99 0.98 0.98 0.98 0.98 0.98 0.97 0.97 0.97 0.97 0.97 0.97 0.97\n",
      " 0.97 0.96 0.96 0.96 0.96 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95\n",
      " 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.94 0.94 0.94 0.93 0.93\n",
      " 0.92 0.92 0.92 0.92 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.91\n",
      " 0.91 0.91 0.91 0.91 0.91 0.91 0.91 0.9  0.9  0.9  0.9  0.9  0.9  0.9\n",
      " 0.9  0.9  0.9  0.89 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.88 0.87\n",
      " 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.87 0.86 0.85 0.84 0.84 0.84\n",
      " 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84 0.84\n",
      " 0.84 0.84 0.84 0.84 0.84 0.84 0.83 0.82 0.82 0.82 0.81 0.81 0.8  0.79\n",
      " 0.78 0.78 0.78 0.78 0.77 0.76 0.76 0.76 0.76 0.75 0.74 0.74 0.73 0.73\n",
      " 0.73 0.73 0.72 0.72 0.72 0.72 0.71 0.71 0.71 0.7  0.69 0.69 0.69 0.69\n",
      " 0.69 0.69 0.68 0.67 0.66 0.65 0.65 0.64 0.63 0.63 0.63 0.62 0.62 0.61\n",
      " 0.6  0.6  0.6  0.59 0.59 0.58 0.57 0.57 0.57 0.56 0.56 0.55 0.54 0.53\n",
      " 0.53 0.52 0.51 0.5  0.49 0.48 0.47 0.47 0.46 0.46 0.45 0.44 0.43 0.42\n",
      " 0.42 0.42 0.42 0.41 0.4  0.39 0.38 0.37 0.36 0.35 0.34 0.33 0.32 0.31\n",
      " 0.3  0.29 0.28 0.27 0.26 0.25 0.24 0.23 0.22 0.21 0.2  0.19 0.18 0.17\n",
      " 0.16 0.15 0.14 0.13 0.12 0.11 0.1  0.09 0.08 0.07 0.06 0.05 0.04 0.03\n",
      " 0.02 0.01 0.  ]\n",
      "threshold [0.11577749 0.12017545 0.12551086 0.12668596 0.13278839 0.13846148\n",
      " 0.13990783 0.14098835 0.14146819 0.14183887 0.14897733 0.15411155\n",
      " 0.15542541 0.1576869  0.15837945 0.15915765 0.16290039 0.16292204\n",
      " 0.16582399 0.16835321 0.16872851 0.17262749 0.1726407  0.17283866\n",
      " 0.17742099 0.17909373 0.18330787 0.1833375  0.18345013 0.1836142\n",
      " 0.18368741 0.1839784  0.18491929 0.18512713 0.18676966 0.18699989\n",
      " 0.18806707 0.19207014 0.19285962 0.1957252  0.20233806 0.20363344\n",
      " 0.20694717 0.20727753 0.20758987 0.20781272 0.21049652 0.21242249\n",
      " 0.21268964 0.21313846 0.21479402 0.21792983 0.21863889 0.21938132\n",
      " 0.22266231 0.22393107 0.22423156 0.22428665 0.22437161 0.2252848\n",
      " 0.22965205 0.2301005  0.23087302 0.23098776 0.23099479 0.23139343\n",
      " 0.23520586 0.23538273 0.23628098 0.24163102 0.24170355 0.24177367\n",
      " 0.24186319 0.24789595 0.25426325 0.25426577 0.25439647 0.25863053\n",
      " 0.26009321 0.26029802 0.2643244  0.26728748 0.2672982  0.27755575\n",
      " 0.28441037 0.29082796 0.29437427 0.29792437 0.30181434 0.30474631\n",
      " 0.3165374  0.31845916 0.31874506 0.32071593 0.32772452 0.33392429\n",
      " 0.33502746 0.33989982 0.35321489 0.35340419 0.35550814 0.36272259\n",
      " 0.36518229 0.36784089 0.37383884 0.37424998 0.37607755 0.37657226\n",
      " 0.37793683 0.39131677 0.39150783 0.39524308 0.39840546 0.40120751\n",
      " 0.40180064 0.41697977 0.41996576 0.42205321 0.42427537 0.43330651\n",
      " 0.43553967 0.43555501 0.43593858 0.43677544 0.43778717 0.450798\n",
      " 0.45119583 0.45591392 0.46777295 0.48662502 0.48922964 0.50329083\n",
      " 0.50488624 0.50994026 0.52701295 0.52740758 0.52780218 0.53135196\n",
      " 0.53739872 0.53981682 0.54563129 0.56857921 0.59996698 0.60246443\n",
      " 0.60845477 0.61131504 0.61780313 0.62694007 0.62840467 0.63223813\n",
      " 0.63569485 0.63720411 0.64314859 0.65333024 0.66392438 0.66858866\n",
      " 0.68105336 0.6818651  0.68346137 0.68581137 0.68612481 0.69095117\n",
      " 0.69279847 0.69474281 0.69563173 0.69564439 0.69923608 0.70908256\n",
      " 0.71171742 0.71699835 0.71964048 0.73318844 0.7443718  0.74509659\n",
      " 0.74634997 0.7467569  0.74837127 0.75058767 0.75235404 0.75236141\n",
      " 0.75243763 0.75258995 0.75483329 0.76893877 0.77520869 0.77946893\n",
      " 0.78180639 0.79105225 0.7914962  0.79518634 0.80139954 0.80598371\n",
      " 0.80715817 0.81416669 0.81511141 0.8160447  0.8190666  0.82151726\n",
      " 0.82568197 0.82608659 0.83368358 0.83451674 0.8397119  0.84780927\n",
      " 0.8556356  0.85604061 0.85684063 0.85927875 0.85990801 0.86004147\n",
      " 0.86098891 0.86634865 0.86690648 0.88965958 0.90188182 0.90830084\n",
      " 0.91442933 0.91537799 0.91540516 0.91857048 0.92150629 0.92251126\n",
      " 0.92525173 0.93018448 0.93370943 0.93533363 0.93879136 0.94109823\n",
      " 0.94190975 0.94264458 0.94571955 0.94674908 0.95416867 0.95513439\n",
      " 0.95540024 0.95674363 0.95826366 0.96062833 0.97114553 0.98514722]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.80      0.82       168\n",
      "          1       0.69      0.76      0.72       100\n",
      "\n",
      "avg / total       0.79      0.78      0.79       268\n",
      "\n",
      "\n",
      "auc 0.8527\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8529bf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_SGD, result ,result_std = sgd(X_train_scaler, y_train, X_test_scaler, y_test, best_param_SGD, X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構築結果を出力\n",
    "output_path = os.path.join(output_dir, \"result_std.csv\")\n",
    "result_std.to_csv(output_path, encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85185185 0.81481481 0.7037037  0.7037037  0.81481481 0.74074074\n",
      " 0.85185185 0.7037037  0.80769231 0.73076923]\n",
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# 交差検証\n",
    "cross_scores = cross_val_score(clf_SGD, X_test_scaler, (np.array(y_test.iloc[:,0].values.flatten())), cv=10)\n",
    "print cross_scores\n",
    "print (\"Accuracy: %0.2f\" % (cross_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木のパラメータリスト\n",
    "depth_range = range(2,10)\n",
    "dt_parameter = [{'n_estimators':[5, 10, 100, 150], 'max_depth':[depth_range]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree (x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    # モデル構築\n",
    "    clf = DecisionTreeClassifier(max_depth=5, random_state=0, class_weight='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predicted = clf.predict(z_test)\n",
    "    #print \"識別率：\", float(sum(predicted == np.array(y_test.iloc[:,0]).T))/len(y_test)\n",
    "    dot_data = StringIO()\n",
    "    tree.export_graphviz(clf, out_file = dot_data, feature_names=list(x_data.columns), filled=True, rounded=True,impurity=False)\n",
    "    res = dot_data.getvalue()\n",
    "    res_en = res.encode(\"cp932\")\n",
    "    res_rep = res_en.replace(\"fontname=helvetica\",\"fontname=meiryo\")\n",
    "    \n",
    "    print \"accuracy_score:\", round(clf.score(x_test,y_test),4)\n",
    "    print \"confusion_matrix:\"\n",
    "    print confusion_matrix(y_test,clf.predict(x_test))\n",
    "    print \"\"\n",
    "    prob = clf.predict_proba(x_test)[:,1]\n",
    "    fpr,tpr,thresholds = roc_curve(y_test,prob)\n",
    "    print \"auc:\", round(sauc(fpr,tpr),4)\n",
    "    \n",
    "    # 変数重要度\n",
    "    column_importance = pd.DataFrame(clf.feature_importances_).T\n",
    "    column_importance.columns = list(x_train.columns)\n",
    "    column_importance_wk = tes.T.reset_index(drop=False)\n",
    "    column_importance_wk.columns = [\"col_name\",\"feature_importances\"]\n",
    "    column_importance_sort = column_importance_wk.sort_values(by=\"feature_importances\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return res_rep, column_importance_sort"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 決定木　（recall固定）\n",
    "def decisionTree(X_train, X_test, y_train, y_test, recall_50, recall_90):\n",
    "    clf = DecisionTreeClassifier(max_depth=5, random_state=0, class_weight='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    print \"識別率：\", float(sum(predicted == np.array(y_test.iloc[:,0]).T))/len(y_test)\n",
    "    \n",
    "    # グラフ描画用\n",
    "    dot_data = StringIO()\n",
    "    tree.export_graphviz(clf, out_file = dot_data, feature_names=list(X.columns), filled=True, rounded=True,impurity=False)\n",
    "    res = dot_data.getvalue()\n",
    "    res_en = res.encode(\"cp932\")\n",
    "    res_rep =res_en.replace(\"fontname=helvetica\",\"fontname=meiryo\")\n",
    "    \n",
    "    prob = clf.predict_proba(X_test)[:,1]\n",
    "    fpr,tpr,thresholds = roc_curve(y_test, prob)\n",
    "    print \"auc: \",(auc(fpr, tpr))\n",
    "\n",
    "    col_name = \"DecisionTree\"\n",
    "    # recall:50%の評価\n",
    "    thre_50 = get_recall_value(X_test, y_test, clf, recall_50)#probの指定\n",
    "    print \"recall:\",recall_50,\" -> 閾値\",thre_50\n",
    "    score_recall_50 = score_result(X_test, y_test, clf, col_name, thre_50, recall_50)\n",
    "    \n",
    "    # recall:90%の評価\n",
    "    thre_90 = get_recall_value(X_test, y_test, clf, recall_90)\n",
    "    print \"recall:\",recall_90,\" -> 閾値\",thre_90\n",
    "    score_recall_90 = score_result(X_test, y_test, clf, col_name, thre_90, recall_90)  \n",
    "    \n",
    "    return clf, res_rep, score_recall_50, score_recall_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
