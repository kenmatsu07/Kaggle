{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "print (sklearn.__version__)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import  SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ名\n",
    "input_dir = ur\"C:/Users/mirait/wk/git/input/\"\n",
    "output_dir = ur\"C:/Users/mirait/wk/git/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータを読み込む\n",
    "test_path = input_dir + ur\"test.csv\"\n",
    "test_data = pd.read_csv(test_path, encoding=\"cp932\",low_memory=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データと条件を同一にするために、訓練データを読み込み項目抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗客番号は出力結果に必要なため退避する\n",
    "passengerId = test_data['PassengerId'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データを読み込む\n",
    "train_path = input_dir + ur\"train_column.csv\"\n",
    "train_data = pd.read_csv(train_path, encoding=\"cp932\",low_memory=False)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータから訓練データの項目のみ抽出する\n",
    "train_columns = list(train_data.columns)\n",
    "test_clean = test_data.loc[:, train_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print test_clean.columns\n",
    "print test_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数はテストデータに元々存在しないため削除\n",
    "test_wk = test_clean.copy()\n",
    "# y = test_wk[\"Survived\"].fillna(0)\n",
    "test_wk = test_wk.drop(columns = {\"Survived\"},axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値が存在する項目（Age）は平均値で置換\n",
    "test_wk[\"Age\"] = test_wk[\"Age\"].fillna(test_wk[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データではFareには欠損値がなかったため完全な同一条件ではなくなるが、\n",
    "# 1件のみのため影響は軽微と判断し平均値で置換\n",
    "# （乗客番号全ての結果を出力する必要があるため削除はNG）\n",
    "test_wk[\"Fare\"] = test_wk[\"Fare\"].fillna(test_wk[\"Fare\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値が存在しないことを確認\n",
    "print test_wk.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ型が定義されているファイルを読み込み　（データ型は独自判断）\n",
    "type_list = input_dir + ur\"type_list.csv\"\n",
    "df_type = pd.read_csv(type_list, encoding=\"cp932\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ項目を抽出\n",
    "clean_test_column = set(list(test_wk.columns))\n",
    "type_char = df_type.query('type == \"char\"')\n",
    "char_column = set(list(type_char[\"column_name\"]))\n",
    "char_match_lis = list(clean_test_column & char_column)\n",
    "print \"入力ファイルの項目数　：　CHAR型の項目数　：\", len(test_wk.columns), \"：\", len(char_match_lis)\n",
    "test_char = test_wk.loc[:,char_match_lis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値項目を抽出\n",
    "type_num = df_type.query('type == \"number\"')\n",
    "num_type_column = set(list(type_num[\"column_name\"]))\n",
    "test_num = test_wk.loc[:, num_type_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_ex = test_char.astype('unicode')\n",
    "# フラグ値ではないため先頭値は削除しない\n",
    "char_ex_dum = pd.get_dummies(char_ex, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マージ\n",
    "merge_file = pd.concat([test_num, char_ex_dum], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(merge_file)\n",
    "print len(merge_file.columns)\n",
    "print merge_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを読み込む\n",
    "model = joblib.load(ur\"model_gbdt.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値項目の標準化のため、カラム単位でデータ型を分離\n",
    "X_column = list(merge_file.columns)\n",
    "num_column = set(list(test_num.columns))\n",
    "char_column = set(X_column) - set(num_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ項目を退避\n",
    "use_char = merge_file.loc[:, char_column].reset_index(drop=True)\n",
    "print len(use_char)\n",
    "print len(use_char.columns)\n",
    "\n",
    "# 数値項目を標準化\n",
    "use_num = merge_file.loc[:, num_column].reset_index(drop=True)\n",
    "print len(use_num)\n",
    "print len(use_num.columns)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_scaler = scaler.fit_transform(use_num)\n",
    "df_scaler = pd.DataFrame(num_scaler)\n",
    "\n",
    "df_scaler.columns = num_column\n",
    "\n",
    "print len(df_scaler)\n",
    "print len(df_scaler.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化後の数値項目とカテゴリ項目を結合\n",
    "X = pd.concat([df_scaler,use_char], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X.head()\n",
    "print len(X)\n",
    "print len(X.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 取り込んだモデルでデータを予測 (不均衡データ評価版)\n",
    "def model_predict(clf, x, y):\n",
    "    prob = clf.predict_proba(x)[:,1]\n",
    "    fpr,tpr,thresholds = roc_curve(y, prob)\n",
    "\n",
    "    fpr_df = pd.DataFrame(fpr)\n",
    "    tpr_df = pd.DataFrame(tpr)\n",
    "    there_df = pd.DataFrame(thresholds)\n",
    "    df_roc = pd.concat([fpr_df, tpr_df, there_df], axis=1)\n",
    "    df_roc.columns = [\"fpr\",\"tpr\",\"thresholds\"]\n",
    "\n",
    "    # recall:50%での閾値を取得\n",
    "    over_recall = (df_roc.query('tpr >= @recall_50')).reset_index(drop=True)\n",
    "    thresholds_n = round((over_recall[\"thresholds\"][0]),3)\n",
    "    print \"閾値：\", thresholds_n\n",
    "\n",
    "    # 作成時の閾値を基に予測する\n",
    "     y_prob = (clf.predict_proba(x)[:,1] >= target_thresholds).astype(int)\n",
    "\n",
    "    # 閾値のモデル精度\n",
    "    ac_score = round((accuracy_score(y, prob)), 3)\n",
    "    pre_score = round((precision_score(y, prob)), 3)\n",
    "    rec_score = round((recall_score(y, prob)), 3)\n",
    "    f1_s = round((f1_score(y, prob)), 3)\n",
    "\n",
    "    # predict_probaでaucを算出\n",
    "    prob = clf.predict_proba(x)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y,prob)\n",
    "    auc_score = round(auc(fpr,tpr),3)\n",
    "    \n",
    "    return prob, ac_score, pre_score, rec_score, f1_s, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルから生存予測\n",
    "y_predict = model.predict(X)\n",
    "y_predict.columns = [\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗客番号と予測結果を結合\n",
    "y_re = pd.Series(y_predict)\n",
    "# y_re = y_predict.reshape(len(y_predict),1)\n",
    "result = pd.concat([passengerId, y_re], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
