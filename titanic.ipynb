{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "print (sklearn.__version__)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import  SVC\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ名\n",
    "input_dir = ur\"C:/Users/mirait/wk/forKaggle/input/\"\n",
    "output_dir = ur\"C:/Users/mirait/wk/forKaggle/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データを読み込む\n",
    "train_path = input_dir + ur\"train.csv\"\n",
    "train_data = pd.read_csv(train_path, encoding=\"cp932\",low_memory=False)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータを読み込む\n",
    "test_path = input_dir + ur\"test.csv\"\n",
    "test_data = pd.read_csv(test_path, encoding=\"cp932\",low_memory=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ：レコード長 891\n",
      "訓練データ：カラム数 12\n",
      "テストデータ：レコード長 418\n",
      "テストデータ：カラム数 11\n"
     ]
    }
   ],
   "source": [
    "print \"訓練データ：レコード長\", len(train_data)\n",
    "print \"訓練データ：カラム数\",len(train_data.columns)\n",
    "print \"テストデータ：レコード長\", len(test_data)\n",
    "print \"テストデータ：カラム数\",len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析に生かすために項目の特徴量を取得\n",
    "def feature(df):\n",
    "    \n",
    "    df_feature = pd.DataFrame()\n",
    "    \n",
    "    for i in (range(len(df.columns))):\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp = df.iloc[:, [i]]\n",
    "        \n",
    "        selList = list()\n",
    "        record_cn = len(tmp) #レコード数\n",
    "        column_name = tmp.columns[0] #カラム名\n",
    "        value_type_cn = len(pd.value_counts(tmp.values.flatten())) #値の種類数(NAはカウント外)\n",
    "        NA_cn = tmp.isnull().sum().values[0] #NA件数\n",
    "\n",
    "        feature_list = list([record_cn, column_name, value_type_cn, NA_cn])\n",
    "        now_column = pd.DataFrame(feature_list).T\n",
    "        #print res1\n",
    "        \n",
    "        df_feature = pd.concat([df_feature, now_column], ignore_index=True)\n",
    "    \n",
    "    df_feature.columns = [u'レコード数', u'カラム名', 'v_count', u'NA件数']\n",
    "        \n",
    "    col_names = list(df_feature.columns)\n",
    "    df_feature = df_feature.loc[:, col_names]\n",
    "\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 訓練データの特徴量\n",
    "feature_train = feature(train_data)\n",
    "print len(feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# テストデータの特徴量\n",
    "feature_test = feature(test_data)\n",
    "print len(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_train = os.path.join(output_dir, \"column_feature_train.csv\")\n",
    "feature_train.to_csv(output_feature_train, encoding=\"cp932\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_test = os.path.join(output_dir, \"column_feature_test.csv\")\n",
    "feature_test.to_csv(output_feature_test, encoding=\"cp932\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ型が定義されているファイルを読み込み　（データ型は独自判断）\n",
    "type_list = input_dir + ur\"type_list.csv\"\n",
    "df_type = pd.read_csv(type_list, encoding=\"cp932\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survived</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fare</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>char</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    column_name    type\n",
       "0   PassengerId    char\n",
       "1      Survived    char\n",
       "2        Pclass    char\n",
       "3          Name    char\n",
       "4           Sex    char\n",
       "5           Age  number\n",
       "6         SibSp  number\n",
       "7         Parch  number\n",
       "8        Ticket    char\n",
       "9          Fare  number\n",
       "10        Cabin    char\n",
       "11     Embarked    char"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_char = df_type.query('type == \"char\"')\n",
    "char_type_column = set(list(type_char[\"column_name\"]))\n",
    "train_char = train_data.loc[:, char_type_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 値の種類数が100以上の項目は除外対象とする　（カテゴリ項目のみ）\n",
    "over_value100_list = list(feature_train.query(\"v_count >= 100\")[u\"カラム名\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ項目を抽出し除外\n",
    "char_column = list(train_char.columns)\n",
    "del_char = list(set(char_column) & set(over_value100_list))\n",
    "wk_set = set(list(train_data.columns)) - set(del_char)\n",
    "wk_sel = list(wk_set)\n",
    "clean_train = train_data.loc[:, wk_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fare Embarked   Age  Parch  Pclass     Sex  Survived  SibSp\n",
      "0   7.2500        S  22.0      0       3    male         0      1\n",
      "1  71.2833        C  38.0      0       1  female         1      1\n",
      "2   7.9250        S  26.0      0       3  female         1      0\n",
      "3  53.1000        S  35.0      0       1  female         1      1\n",
      "4   8.0500        S  35.0      0       3    male         0      0\n",
      "Index([u'Fare', u'Embarked', u'Age', u'Parch', u'Pclass', u'Sex', u'Survived',\n",
      "       u'SibSp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print clean_train.head()\n",
    "print clean_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字列（Embarked）の最頻値を抽出するのは実装上困難なため、replaceで代替\n",
    "pd.value_counts(clean_train[\"Embarked\"]) # \"S\"\n",
    "clean_train[\"Embarked\"] = clean_train[\"Embarked\"].replace([np.nan],\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値が存在する項目（Age）は平均値で置換\n",
    "clean_train[\"Age\"] = clean_train[\"Age\"].fillna(clean_train[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fare        False\n",
      "Embarked    False\n",
      "Age         False\n",
      "Parch       False\n",
      "Pclass      False\n",
      "Sex         False\n",
      "Survived    False\n",
      "SibSp       False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 欠損値が存在しないことを確認\n",
    "print clean_train.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数\"Survived\"がダミー変数化対象になるため退避\n",
    "target = clean_train[\"Survived\"]\n",
    "clean_train_wk = clean_train.drop(columns = {\"Survived\"},axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 値0 549\n",
      "値1 342\n"
     ]
    }
   ],
   "source": [
    "# 目的変数の値を確認\n",
    "print \"値0\", len(clean_train.query('Survived == 0'))\n",
    "print \"値1\", len(clean_train.query('Survived == 1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力ファイルの項目数　：　CHAR型の項目数　： 7 ： 3\n"
     ]
    }
   ],
   "source": [
    "# カテゴリ項目を抽出\n",
    "clean_train_column = set(list(clean_train_wk.columns))\n",
    "char_column = set(list(type_char[\"column_name\"]))\n",
    "char_match_lis2 = list(clean_train_column & char_column)\n",
    "print \"入力ファイルの項目数　：　CHAR型の項目数　：\", len(clean_train_wk.columns), \"：\", len(char_match_lis2)\n",
    "char_column_lis2 = clean_train_wk.loc[:,char_match_lis2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値項目を抽出\n",
    "type_num = df_type.query('type == \"number\"')\n",
    "num_type_column = set(list(type_num[\"column_name\"]))\n",
    "train_num = clean_train_wk.loc[:, num_type_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_ex = char_column_lis2.astype('unicode')\n",
    "# フラグ値ではないため先頭値は削除しない\n",
    "char_ex_dum = pd.get_dummies(char_ex, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マージ\n",
    "merge_file = pd.concat([train_num,char_ex_dum], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "12\n",
      "      Fare   Age  SibSp  Parch  Sex_female  Sex_male  Pclass_1  Pclass_2  \\\n",
      "0   7.2500  22.0      1      0           0         1         0         0   \n",
      "1  71.2833  38.0      1      0           1         0         1         0   \n",
      "2   7.9250  26.0      0      0           1         0         0         0   \n",
      "3  53.1000  35.0      1      0           1         0         1         0   \n",
      "4   8.0500  35.0      0      0           0         1         0         0   \n",
      "\n",
      "   Pclass_3  Embarked_C  Embarked_Q  Embarked_S  \n",
      "0         1           0           0           1  \n",
      "1         0           1           0           0  \n",
      "2         1           0           0           1  \n",
      "3         0           0           0           1  \n",
      "4         1           0           0           1  \n"
     ]
    }
   ],
   "source": [
    "print len(merge_file)\n",
    "print len(merge_file.columns)\n",
    "print merge_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ分割\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(merge_file, target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値項目の標準化のため、カラム単位でデータ型を分離\n",
    "X_column = list(merge_file.columns)\n",
    "num_column = set(list(train_num.columns))\n",
    "char_column = set(X_column) - set(num_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値項目において訓練データの平均値/標準偏差から訓練データ、テストデータのz-scoreを算出し標準化する\n",
    "# StandardScalerは上記が実現不可のため個別実装\n",
    "def number_scaler(X_train, X_test):\n",
    "    \n",
    "    train_scaler = pd.DataFrame()\n",
    "    test_scaler = pd.DataFrame()\n",
    "    \n",
    "    train_num = X_train.loc[:, num_column]\n",
    "    test_num = X_test.loc[:, num_column]\n",
    "    \n",
    "    # 標準化後にカテゴリ項目をマージさせるために定義\n",
    "    train_char = X_train.loc[:, char_column]\n",
    "    test_char = X_test.loc[:, char_column]\n",
    "    \n",
    "    # 訓練データの平均値、標準偏差を取得\n",
    "    for i in train_num.columns:        \n",
    "        train_mean = train_num[i].mean()\n",
    "        train_std = train_num[i].std()\n",
    "        \n",
    "        # z-scoreを求める\n",
    "        train_z = pd.DataFrame({i:(train_num[i] - train_mean) / train_std})\n",
    "        test_z = pd.DataFrame({i:(test_num[i] - train_mean) / train_std})\n",
    "        \n",
    "        train_scaler = pd.concat([train_scaler, train_z], axis=1)\n",
    "        test_scaler = pd.concat([test_scaler, test_z], axis=1)\n",
    "    \n",
    "    # カテゴリ項目をマージ\n",
    "    train_scaler = pd.concat([train_scaler,train_char], axis=1)\n",
    "    test_scaler = pd.concat([test_scaler,test_char], axis=1)\n",
    "    \n",
    "    # 訓練データの分割次第で標準偏差が0となり、z-scoreが'Nan'となるため0埋めする\n",
    "    train_scaler = train_scaler.fillna(0)\n",
    "    test_scaler = test_scaler.fillna(0)\n",
    "    \n",
    "#     df_std = pd.DataFrame(lis).T\n",
    "#     df_std.columns = num_list\n",
    "#     df_std= df_std.T.reset_index(drop=False)\n",
    "#     df_std.columns =[\"col_name\",\"std\"]\n",
    "    \n",
    "#     print \"train:\",len(df01)\n",
    "#     print \"test:\",len(df02)\n",
    "\n",
    "    \n",
    "    return train_scaler, test_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ\n",
    "def grid_s(sc_list, model, grid_param, cv, X, y):\n",
    "    score = sc_list[0]\n",
    "    gs = GridSearchCV(model, grid_param, cv=cv, scoring=score)\n",
    "    gs.fit(X_train,y_train)\n",
    "    result = pd.DataFrame(gs.grid_scores_)\n",
    "    result = result.rename(columns={'mean_validation_score':score})\n",
    "    result = result.iloc[:,[0,1]]\n",
    "    print gs.best_params_\n",
    "    \n",
    "    for i in sc_list[1:]:\n",
    "        score = i\n",
    "        gs = GridSearchCV(model, grid_param, cv=cv, scoring=score)\n",
    "        gs.fit(X_train,y_train)\n",
    "        res = pd.DataFrame(gs.grid_scores_)\n",
    "        res = res.rename(columns={'mean_validation_score':score})\n",
    "        res = res.iloc[:,[1]]\n",
    "        result = pd.concat([result,res],axis=1)\n",
    "    \n",
    "    return result, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引数としたrecall値の閾値を取得\n",
    "def get_recall_value(X_test_scaler, y_test, clf ,recall_n):\n",
    "    \n",
    "    # 任意の閾値のprecision、recallを取得\n",
    "    prob = clf.predict_proba(X_test_scaler)[:,1]\n",
    "    fpr,tpr,thresholds = roc_curve(y_test, prob)\n",
    "\n",
    "    fpr_df = pd.DataFrame(fpr)\n",
    "    tpr_df = pd.DataFrame(tpr)\n",
    "    there_df = pd.DataFrame(thresholds)\n",
    "    df_roc = pd.concat([fpr_df, tpr_df, there_df], axis=1)\n",
    "    df_roc.columns = [\"fpr\",\"tpr\",\"thresholds\"]\n",
    "    \n",
    "    over_recall = (df_roc.query('tpr >= @recall_n ')).reset_index(drop=True)\n",
    "    print len(over_recall)\n",
    "\n",
    "    # 閾値を取得\n",
    "    thresholds_n = round((over_recall[\"thresholds\"][0]),3)\n",
    "    \n",
    "    print thresholds_n\n",
    "    return thresholds_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル評価\n",
    "def score_result(X_test_scaler, y_test, clf, col_name, thresholds_n, recall_n):\n",
    "    \n",
    "    # recall固定値\n",
    "    fix_recall = str(recall_n * 100)+\"%\"\n",
    "    \n",
    "    y_prob = (clf.predict_proba(X_test_scaler)[:,1] >= thresholds_n).astype(int)\n",
    "    \n",
    "    # 閾値のモデル精度\n",
    "    ac_score = round((accuracy_score(y_test, y_prob)), 3)\n",
    "    pre_score = round((precision_score(y_test, y_prob)), 3)\n",
    "    rec_score = round((recall_score(y_test, y_prob)), 3)\n",
    "    f1_s = round((f1_score(y_test, y_prob)), 3)\n",
    "    \n",
    "    # predict_probaでaucを算出\n",
    "    prob = clf.predict_proba(X_test_scaler)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,prob)\n",
    "    auc_score = round(auc(fpr,tpr),3)\n",
    "    \n",
    "    tmp = [fix_recall, auc_score, ac_score, pre_score, rec_score, f1_s]\n",
    "    score_df = pd.DataFrame(tmp)\n",
    "    score_df.index = [\"fix_Recall\", \"AUC\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_score\"]\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(model, x_data, y_data):\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "        \n",
    "    print \"score:\", model.score(X_test,y_test)\n",
    "    print \"confusion_matrix:\"\n",
    "    print confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "    coeff_df = pd.DataFrame([X_train.columns,  model.coef_[0]]).T\n",
    "    coeff_df.columns = [\"col_name\",\"coef\"] \n",
    "    coeff_df[\"coef_abs\"] = abs(coeff_df[\"coef\"] )\n",
    "    coeff_df1 = coeff_df.sort_values(by=\"coef_abs\", ascending=False).reset_index(drop=True)\n",
    "    coeff_df2 = pd.merge(coeff_df1,X_std, on=\"col_name\", how=\"left\")\n",
    "    coeff_df2[\"coef/std\"] = coeff_df2[\"coef\"]/coeff_df2[\"std\"]\n",
    "    for i in range(len(coeff_df2)):\n",
    "        if np.isnan(coeff_df2.loc[i,\"coef/std\"]) == True:\n",
    "            coeff_df2.loc[i,\"coef/std\"] = coeff_df2.loc[i,\"coef\"]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    print \"\"\n",
    "    print \"回帰係数の総数\",len(coeff_df1)\n",
    "    coeff_df1.coef =coeff_df1.coef.astype(np.float)\n",
    "    print \"回帰係数 0の数\",len(coeff_df1.query('coef == 0'))\n",
    "    print \"回帰係数 0以外の数\",len(coeff_df1.query('coef != 0'))\n",
    "    \n",
    "    \n",
    "    print \"\"\n",
    "    precision, recall, threshold = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1] )#\n",
    "\n",
    "    print \"precision \",precision\n",
    "    print \"recall_\",recall\n",
    "    print \"threshold\",threshold\n",
    "    \n",
    "    print \"\"\n",
    "    print (sklearn.metrics.classification_report(y_test, model.predict(X_test)))\n",
    "    \n",
    "    print \"\"\n",
    "    prob = model.predict_proba(X_test)[:,1]\n",
    "    fpr,tpr,thresholds = sklearn.metrics.roc_curve(y_test,prob)\n",
    "    print \"auc\", round(sklearn.metrics.auc(fpr,tpr),4)\n",
    "    \n",
    "    #print \"\"\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"ROC curve\")\n",
    "\n",
    "    plt.xlabel(\"False Positve Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    #plt.show()\n",
    "    \n",
    "    return coeff_df1,coeff_df2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# SGD (エラスティックネット) (recall評価版)\n",
    "def sgd(X_train_scaler, X_test_scaler, y_train, y_test, recall_50, recall_90):\n",
    "    \n",
    "    clf =linear_model.SGDClassifier(loss='log', penalty='elasticnet', random_state=0, class_weight='balanced',\n",
    "                                    alpha=grid_sgd_param[u'alpha'] , l1_ratio=grid_sgd_param[u'l1_ratio'], max_iter=500)\n",
    "    clf.fit(X_train_scaler,y_train)\n",
    "    \n",
    "    # 項目毎の回帰係数を出力\n",
    "    coeff_df = pd.DataFrame([X_train_scaler.columns, clf.coef_[0]]).T\n",
    "    coeff_df.columns = [\"col_name\",\"coef\"] \n",
    "    coeff_df[\"coef_abs\"] = abs(coeff_df[\"coef\"] )\n",
    "    coeff_df_sort = coeff_df.sort_values(by=\"coef_abs\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print \"回帰係数の総数\",len(coeff_df_sort)\n",
    "    coeff_df_sort.coef =coeff_df_sort.coef.astype(np.float)\n",
    "    print \"回帰係数 0の数\",len(coeff_df_sort.query('coef == 0'))\n",
    "    print \"回帰係数 0以外の数\",len(coeff_df_sort.query('coef != 0'))\n",
    "    \n",
    "    col_name = \"SGDClassifier\"\n",
    "    \n",
    "    # recall:50%の評価\n",
    "    thre_50 = get_recall_value(X_test_scaler, y_test, clf, recall_50)#probの指定\n",
    "    print \"recall:\",recall_50,\" -> 閾値\",thre_50\n",
    "    score_recall_50 = score_result(X_test_scaler, y_test, clf, col_name, thre_50, recall_50)\n",
    "    \n",
    "    # recall:90%の評価\n",
    "    thre_90 = get_recall_value(X_test_scaler, y_test, clf, recall_90)\n",
    "    print \"recall:\",recall_90,\" -> 閾値\",thre_90\n",
    "    score_recall_90 = score_result(X_test_scaler, y_test, clf, col_name, thre_90, recall_90)    \n",
    "    \n",
    "    # AUC値を取得\n",
    "    prob = clf.predict_proba(X_test_scaler)[:,1]\n",
    "    fpr,tpr,thresholds = sklearn.metrics.roc_curve(y_test,prob)\n",
    "    print \"auc\", round(sklearn.metrics.auc(fpr,tpr),4)\n",
    "    \n",
    "    # ROC曲線を出力\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel(\"False Positve Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    \n",
    "    return coeff_df_sort, score_recall_50, score_recall_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値項目を標準化\n",
    "X_train_scaler, X_test_scaler = number_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Fare', u'Age', u'SibSp', u'Parch', u'Pclass_1', u'Embarked_Q',\n",
      "       u'Pclass_3', u'Pclass_2', u'Sex_male', u'Sex_female', u'Embarked_S',\n",
      "       u'Embarked_C'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print X_train_scaler.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価値\n",
    "#sc_list = ['roc_auc','accuracy','f1']\n",
    "sc_list = ['accuracy']\n",
    "# 交差検定の実行回数\n",
    "cv  = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ用のモデル\n",
    "grid_SGD_clf = linear_model.SGDClassifier(loss='log', penalty='elasticnet', random_state=0, class_weight='balanced',max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化したいパラメータのリスト\n",
    "param = [{'alpha': [0.1, 0.01, 0.001],'l1_ratio': [0, 0.05, 0.1, 0.15]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01, 'l1_ratio': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirait\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_result_SGD, best_param_SGD = grid_s(sc_list, clf, param, cv, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチの探索結果を出力\n",
    "output_grid = os.path.join(output_dir, \"grid_SGD.csv\")\n",
    "grid_result_SGD.to_csv(output_grid, encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#グリッドサーチで確認したacuが最も高いパラメータを追加\n",
    "SGD_clf = linear_model.SGDClassifier(loss='log', penalty='elasticnet', random_state=0, \n",
    "                                     alpha = best_param_SGD['alpha'], l1_ratio = best_param_SGD['l1_ratio'],class_weight='balanced',max_iter=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# テストデータの欠損値を削除した上で目的変数に欠損値が存在しない行を指定する\n",
    "X_test_scaler = (X_test_scaler.replace([np.inf,-np.inf],np.nan)).dropna()\n",
    "noinf_ix = list(X_test_scaler.index)\n",
    "y_test_loan = y_test_loan.loc[noinf_ix,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n"
     ]
    }
   ],
   "source": [
    "result ,result_std = sgd(X_train_scaler, X_test_scaler, y_train, y_test, SGD_clf, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
