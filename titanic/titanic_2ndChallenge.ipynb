{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "print (sklearn.__version__)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.externals import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import  SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier,AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ名\n",
    "input_dir = ur\"C:/Users/mirait/wk/git/input/\"\n",
    "output_dir = ur\"C:/Users/mirait/wk/git/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データを読み込む\n",
    "train_path = input_dir + ur\"train.csv\"\n",
    "train_data = pd.read_csv(train_path, encoding=\"cp932\",low_memory=False)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータを読み込む\n",
    "test_path = input_dir + ur\"test.csv\"\n",
    "test_data = pd.read_csv(test_path, encoding=\"cp932\",low_memory=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"訓練データ：レコード長\", len(train_data)\n",
    "print \"訓練データ：カラム数\",len(train_data.columns)\n",
    "print \"テストデータ：レコード長\", len(test_data)\n",
    "print \"テストデータ：カラム数\",len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練+テストを結合\n",
    "merge_arr = [train_data, test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析に生かすために項目の特徴量を取得\n",
    "def feature(df):\n",
    "    \n",
    "    df_feature = pd.DataFrame()\n",
    "    \n",
    "    for i in (range(len(df.columns))):\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp = df.iloc[:, [i]]\n",
    "        \n",
    "        selList = list()\n",
    "        record_cn = len(tmp) #レコード数\n",
    "        column_name = tmp.columns[0] #カラム名\n",
    "        value_type_cn = len(pd.value_counts(tmp.values.flatten())) #値の種類数(NAはカウント外)\n",
    "        NA_cn = tmp.isnull().sum().values[0] #NA件数\n",
    "\n",
    "        feature_list = list([record_cn, column_name, value_type_cn, NA_cn])\n",
    "        now_column = pd.DataFrame(feature_list).T\n",
    "        #print res1\n",
    "        \n",
    "        df_feature = pd.concat([df_feature, now_column], ignore_index=True)\n",
    "    \n",
    "    df_feature.columns = [u'レコード数', u'カラム名', 'v_count', u'NA件数']\n",
    "        \n",
    "    col_names = list(df_feature.columns)\n",
    "    df_feature = df_feature.loc[:, col_names]\n",
    "\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データの特徴量\n",
    "feature_train = feature(train_data)\n",
    "print len(feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_train = os.path.join(output_dir, \"column_feature_train.csv\")\n",
    "feature_train.to_csv(output_feature_train, encoding=\"cp932\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの特徴量\n",
    "feature_test = feature(test_data)\n",
    "print len(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_test = os.path.join(output_dir, \"column_feature_test.csv\")\n",
    "feature_test.to_csv(output_feature_test, encoding=\"cp932\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値があるカラムを取得\n",
    "null_columns = [col for col in train_data.columns if train_data[col].isnull().any()]\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「Cabin」の欠損値を埋める\n",
    "train_data['Cabin'] = pd.Series([i[0] if pd.notnull(i) else 'X' for i in train_data['Cabin'] ])\n",
    "train_data['Cabin'].replace('T','X',inplace=True)    # テストデータには\"T\"がないため、欠損値ど同義と捉え\"X\"に置換\n",
    "test_data['Cabin'] = pd.Series([i[0] if pd.notnull(i) else 'X' for i in test_data['Cabin'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「Cabin」のデータ分布を視覚化\n",
    "print(train_data.Cabin.value_counts())\n",
    "sns.countplot('Cabin', data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人物名の敬称を取得\n",
    "for data in merge_arr:\n",
    "    data['Title'] = data.Name.str.split(', ',expand=True)[1].str.split('. ',expand=True)[0]\n",
    "    title_cnt = data.Title.value_counts()<10\n",
    "    data.Title = data.Title.apply(lambda x: x if title_cnt[x]==False else 'Misc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print title_cnt.head()\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年齢の欠損値埋め\n",
    "# チケットクラス、敬称、性別から年齢の平均値をそれぞれ取得して埋める\n",
    "# 単純に平均値で埋めるのではなく、年齢と相関関係が高いと推測される項目から取得 (先に項目間の相関関係を取得する必要あり)\n",
    "med_age = pd.DataFrame()\n",
    "def fill_age(cols):\n",
    "    pclass = cols[0]\n",
    "    sex = cols[1]\n",
    "    age = cols[2]\n",
    "    title = cols[3]\n",
    "    if pd.isnull(age):\n",
    "        return med_age[(med_age['Pclass']==pclass) & (med_age['Title']==title) & (med_age['Sex']==sex)]['Age']\n",
    "    else:\n",
    "        return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in merge_arr:\n",
    "    med_age = dataset.groupby(['Pclass','Title','Sex'])['Age'].median().reset_index()\n",
    "    dataset['Age'] = dataset[['Pclass','Sex','Age','Title']].apply(fill_age,axis=1)\n",
    "    \n",
    "    # Embarkedは欠損値が2つのみのため最頻値で埋める\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace=True)\n",
    "    # 世帯人数に関連する項目を追加\n",
    "    dataset['FamilySize'] = dataset.SibSp+dataset.Parch+1\n",
    "    dataset['IsAlone'] = 1\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize']>1]=0\n",
    "    # 賃金を四分割\n",
    "    dataset['FareBin']=pd.qcut(dataset['Fare'],4,labels=[1,2,3,4])\n",
    "    # 年齢を五分割\n",
    "    dataset['AgeBin']=pd.cut(dataset['Age'],5,labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生存者数の総数を確認\n",
    "print(train_data.Survived.value_counts())\n",
    "sns.countplot(x='Survived',data=train_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性別-生存者数\n",
    "print(train_data.groupby('Sex')['Survived'].sum())\n",
    "sns.countplot(x='Survived',hue='Sex',data=train_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# チケットクラス-生存者数\n",
    "print(train_data.groupby('Pclass')['Survived'].sum())\n",
    "sns.countplot(x='Survived',hue='Pclass',data=train_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 敬称-生存者数\n",
    "print(train_data.groupby('Title')['Survived'].sum())\n",
    "sns.countplot(x='Survived',hue='Title',data=train_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単身者-生存者数\n",
    "print(train_data.groupby('IsAlone')['Survived'].sum())\n",
    "sns.countplot(x='Survived',hue='IsAlone',data=train_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 世帯人数-生存者数\n",
    "print(train_data.groupby('FamilySize')['Survived'].sum())\n",
    "sns.countplot(x='Survived',hue='FamilySize',data=train_data)\n",
    "plt.legend(loc=1) #moving the legned to the right\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Age=train_data.Age.astype(int)\n",
    "# 年齢-生存者数でプロット\n",
    "ageplt = sns.FacetGrid(train_data,hue='Survived',aspect=4)\n",
    "ageplt.map(sns.kdeplot,'Age',shade=True)\n",
    "ageplt.set(xlim=(0,train_data.Age.max()))\n",
    "ageplt.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 賃金-生存者数でプロット\n",
    "fareplt = sns.FacetGrid(train_data,hue='Survived',aspect=5)\n",
    "fareplt.map(sns.kdeplot,'Fare',shade=True)\n",
    "fareplt.set(xlim=(0,train_data.Fare.max()))\n",
    "fareplt.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一意の値と推測できる項目は削除　（'PassengerId','Ticket','Name'）\n",
    "# 新規項目追加時に使用した項目は、新規項目で代替可能なため削除　（'Fare','Age','SibSp','Parch'）\n",
    "train_data.drop(['PassengerId','Ticket','Name','Fare','Age','SibSp','Parch'],axis=1,inplace=True)\n",
    "test_data.drop(['Ticket','Name','Fare','Age','Parch','SibSp'],axis=1,inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダミー変数化\n",
    "train_dum = pd.get_dummies(train_data, columns=['Sex','Embarked','Pclass','Title','AgeBin','FareBin','Cabin'],drop_first=True)\n",
    "test_dum = pd.get_dummies(test_data, columns=['Sex','Embarked','Pclass','Title','AgeBin','FareBin','Cabin'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dum.corr()['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dum.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の処理\n",
    "tmp = train_dum.copy()\n",
    "print len(tmp)\n",
    "tmp01 = tmp.dropna()\n",
    "print len(tmp01),\":NA行数 \",(len(tmp)-len(tmp01))\n",
    "tmp02 = tmp01.replace([np.inf,-np.inf],np.nan)    #infの置換\n",
    "tmp03 = tmp02.dropna().reset_index(drop =True)\n",
    "print len(tmp03),\":inf行数 \",(len(tmp02)-len(tmp03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗客番号は出力に用いるため退避し削除\n",
    "PassengerId = test_data['PassengerId']\n",
    "test_dum.drop(labels=['PassengerId'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数、目的変数への分割\n",
    "X = tmp03.drop(columns = {u\"Survived\"},axis =1)\n",
    "y = tmp03.loc[:,[u\"Survived\"]]\n",
    "\n",
    "print len(X.columns)\n",
    "print len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ分割\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ\n",
    "def grid(x, y, clf, grid_param, cv):\n",
    "    \n",
    "    # パラメータ探索\n",
    "    gs = GridSearchCV(clf, grid_param, cv=cv)\n",
    "    gs.fit(x, y)\n",
    "    \n",
    "    # グリッドサーチの結果を出力\n",
    "    result = pd.DataFrame(gs.grid_scores_)\n",
    "    result = result.iloc[:,[0,1]]\n",
    "    print gs.best_params_\n",
    "    \n",
    "    return result, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD (回帰係数、適合率など評価)\n",
    "def sgd(X_train, y_train, X_test, y_test, param):\n",
    "    \n",
    "    # モデル構築\n",
    "#   clf =linear_model.SGDClassifier(loss='log', penalty='elasticnet', random_state=0, class_weight='balanced',\n",
    "#                                     alpha = param['alpha'] , l1_ratio = param['l1_ratio'], max_iter=500)\n",
    "    clf =linear_model.SGDClassifier(loss='log', penalty='elasticnet', class_weight='balanced',\n",
    "                                    alpha = param['alpha'] , l1_ratio = param['l1_ratio'], max_iter=500)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # モデル評価を出力\n",
    "    print \"score:\", clf.score(X_test,y_test)\n",
    "    print \"confusion_matrix:\"\n",
    "    print confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "    # 回帰係数を出力\n",
    "    coeff_df = pd.DataFrame([X_train.columns,  clf.coef_[0]]).T\n",
    "    coeff_df.columns = [\"col_name\",\"coef\"] \n",
    "    coeff_df[\"coef_abs\"] = abs(coeff_df[\"coef\"] )\n",
    "    coeff_sort = coeff_df.sort_values(by=\"coef_abs\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    print \"\"\n",
    "    print \"回帰係数の総数\",len(coeff_sort)\n",
    "    coeff_sort.coef =coeff_sort.coef.astype(np.float)\n",
    "    print \"回帰係数 0の数\",len(coeff_sort.query('coef == 0'))\n",
    "    print \"回帰係数 0以外の数\",len(coeff_sort.query('coef != 0'))\n",
    "    \n",
    "\n",
    "    # 適合率、再現率、閾値をそれぞれ出力\n",
    "    print \"\"\n",
    "    precision, recall, threshold = precision_recall_curve(y_test, clf.predict_proba(X_test)[:,1] )#\n",
    "    print \"\"\n",
    "    print (classification_report(y_test, clf.predict(X_test)))\n",
    "    \n",
    "    print \"\"\n",
    "    prob = clf.predict_proba(X_test)[:,1]\n",
    "    fpr,tpr,thresholds = sklearn.metrics.roc_curve(y_test,prob)\n",
    "    print \"auc\", round(sklearn.metrics.auc(fpr,tpr),4)\n",
    "    \n",
    "    # ROC曲線\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel(\"False Positve Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    #plt.show()\n",
    "    \n",
    "    return clf, coeff_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交差検定の実行回数\n",
    "cv  = 10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1回目：{'alpha': [0.1, 0.01, 0.001],'l1_ratio': [0, 0.05, 0.1, 0.15]}\n",
    "{'alpha': 0.01, 'l1_ratio': 0.05}\n",
    "\n",
    "2回目：{'alpha': [0.006, 0.01, 0.05],'l1_ratio': [0.03, 0.05, 0.07]}\n",
    "{'alpha': 0.01, 'l1_ratio': 0.07}\n",
    "\n",
    "3回目：{'alpha': [0.009, 0.01, 0.03],'l1_ratio': [0.07, 0.08, 0.09]}\n",
    "{'alpha': 0.009, 'l1_ratio': 0.07}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDのパラメータリスト\n",
    "sgd_param = [{'alpha': [0.001, 0.0001, 0.00001],'l1_ratio': [0, 0.02, 0.04]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ用SGD\n",
    "grid_sgd = linear_model.SGDClassifier(loss='log', penalty='elasticnet', random_state=0, class_weight='balanced',max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print grid_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result_SGD, best_param_SGD = grid(X_train, y_train, grid_sgd, sgd_param, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチの探索結果を出力\n",
    "output_grid = os.path.join(output_dir, \"grid_SGD.csv\")\n",
    "grid_result_SGD.to_csv(output_grid, encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適パラメータでモデル構築\n",
    "clf_SGD, result = sgd(X_train, y_train, X_test, y_test, best_param_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_SGD.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交差検証\n",
    "cross_scores = cross_val_score(clf_SGD, X_test, (np.array(y_test.iloc[:,0].values.flatten())), cv=10)\n",
    "print cross_scores\n",
    "print (\"Accuracy: %0.2f\" % (cross_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree (x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    # モデル構築\n",
    "#     clf = DecisionTreeClassifier(max_depth=5, random_state=0, class_weight='balanced')\n",
    "    clf = DecisionTreeClassifier(max_depth=5, class_weight='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    predicted = clf.predict(x_test)\n",
    "    #print \"識別率：\", float(sum(predicted == np.array(y_test.iloc[:,0]).T))/len(y_test)\n",
    "    dot_data = StringIO()\n",
    "    tree.export_graphviz(clf, out_file = dot_data, feature_names=list(x_train.columns), filled=True, rounded=True,impurity=False)\n",
    "    res = dot_data.getvalue()\n",
    "    res_wk = res.encode(\"cp932\")\n",
    "    dot_file = res_wk.replace(\"fontname=helvetica\",\"fontname=meiryo\")\n",
    "    \n",
    "    print \"accuracy_score:\", round(clf.score(x_test,y_test),4)\n",
    "    print \"confusion_matrix:\"\n",
    "    print confusion_matrix(y_test,clf.predict(x_test))\n",
    "    print \"\"\n",
    "    prob = clf.predict_proba(x_test)[:,1]\n",
    "    fpr,tpr,thresholds = roc_curve(y_test,prob)\n",
    "    print \"auc:\", round(auc(fpr,tpr),4)\n",
    "    \n",
    "    # 変数重要度\n",
    "    column_importance = pd.DataFrame(clf.feature_importances_).T\n",
    "    column_importance.columns = list(x_train.columns)\n",
    "    column_importance_wk = column_importance.T.reset_index(drop=False)\n",
    "    column_importance_wk.columns = [\"col_name\",\"feature_importances\"]\n",
    "    column_importance_sort = column_importance_wk.sort_values(by=\"feature_importances\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return clf, dot_file, column_importance_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt, dot_file, dt_importance = decisionTree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_dt.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ファイル出力\n",
    "f = open('decisionTree.dot','w')\n",
    "f.write(dot_file)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムフォレスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(x_train, x_test, y_train, y_test, param):\n",
    "    clf = RandomForestClassifier(n_estimators = param['n_estimators'], max_depth = param['max_depth'], \n",
    "                                 random_state=0, class_weight='balanced')\n",
    "    clf.fit(x_train, y_train)\n",
    "    prob = clf.predict_proba(x_test)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "    \n",
    "    print \"accuracy_score:\",round(clf.score(x_test,y_test),4)\n",
    "    print \"auc:\", round(auc(fpr,tpr),4)\n",
    "    print \"confusion_matrix:\"\n",
    "    print confusion_matrix(y_test,clf.predict(x_test))\n",
    "    \n",
    "    # ROC曲線を出力\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel(\"False Positve Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量を順位付け\n",
    "def get_feature_importance(x, clf):\n",
    "    col_name = pd.DataFrame(x.columns)\n",
    "    fi = pd.DataFrame(clf.feature_importances_)\n",
    "    df_wk = pd.concat([col_name, fi],axis=1)\n",
    "    df_wk.columns = [\"col_name\",\"feature_importance\"]\n",
    "    importance_list = df_wk.sort_values(by=\"feature_importance\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return importance_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムフォレストのパラメータリスト\n",
    "depth_range = range(2, 13, 1)\n",
    "rf_parameter = [{'n_estimators':[30, 50, 70], 'max_depth':depth_range}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ用ランダムフォレスト\n",
    "grid_rf = RandomForestClassifier(random_state=0, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ探索　（標準化の必要がないため、説明変数は標準化前のデータを使用）\n",
    "grid_result_rf, best_param_rf = grid(X_train, y_train, grid_rf, rf_parameter, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチの探索結果を出力\n",
    "output_grid = os.path.join(output_dir, \"grid_rf.csv\")\n",
    "grid_result_rf.to_csv(output_grid, encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適パラメータでモデル構築\n",
    "clf_rf = randomforest(X_train, X_test, y_train, y_test, best_param_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_rf.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の順位を取得\n",
    "feature_importance = get_feature_importance(X_train, clf_rf)\n",
    "output_path = os.path.join(output_dir, \"feature_importance.csv\")\n",
    "feature_importance.to_csv(output_path, encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_log = LogisticRegression (max_iter=100)\n",
    "clf_log.fit(X_train,y_train)\n",
    "ypred = clf_log.predict(X_test)\n",
    "print(clf_log.score(X_train,y_train))\n",
    "print(confusion_matrix(y_test,ypred))\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbdt(x_train, x_test, y_train, y_test, param):\n",
    "    clf = GradientBoostingClassifier(n_estimators = param['n_estimators'], max_depth = param['max_depth'], \n",
    "                                 random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    prob = clf.predict_proba(x_test)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "    \n",
    "    print \"acc:\",round(clf.score(x_test,y_test),4)\n",
    "    print \"auc:\", round(auc(fpr,tpr),4)\n",
    "    print \"confusion_matrix:\"\n",
    "    print confusion_matrix(y_test,clf.predict(x_test))\n",
    "    \n",
    "    # ROC曲線を出力\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel(\"False Positve Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDTのパラメータリスト\n",
    "depth_range = range(2, 13, 1)\n",
    "gbdt_parameter = [{'n_estimators':[10, 50, 100, 150], 'max_depth':depth_range}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ用GBDT\n",
    "# grid_gbdt = GradientBoostingClassifier(random_state=0)\n",
    "grid_gbdt = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ探索\n",
    "grid_result_gbdt, best_param_gbdt = grid(X_train, y_train, grid_gbdt, gbdt_parameter, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチの探索結果を出力\n",
    "output_grid = os.path.join(output_dir, \"grid_gbdt.csv\")\n",
    "grid_result_gbdt.to_csv(output_grid, encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適パラメータでモデル構築\n",
    "clf_gbdt = gbdt(X_train, X_test, y_train, y_test, best_param_gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_gbdt.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルをエクスポート\n",
    "joblib.dump(clf_gbdt, 'model_gbdt.pkl',compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済モデルを取り込み\n",
    "clf_voting = VotingClassifier(estimators=[('sgd',clf_SGD),('dt',clf_dt),('rf',clf_rf),('log',clf_log),('gbdt',clf_gbdt)],voting='soft',n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルをエクスポート\n",
    "joblib.dump(clf_voting, 'model_voting.pkl',compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = input_dir + ur\"gender_submission.csv\"\n",
    "gen_data = pd.read_csv(gen_path, encoding=\"cp932\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = clf_voting.predict(test_dum)\n",
    "print(confusion_matrix(gen_data.Survived,pred1))\n",
    "print(classification_report(gen_data.Survived,pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗客番号と予測結果を結合\n",
    "y_re = pd.Series(pred1)\n",
    "# y_re = y_predict.reshape(len(y_predict),1)\n",
    "result = pd.concat([PassengerId, y_re], axis=1)\n",
    "result_re = result.rename(columns={0: 'Survived'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print result_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数の値を確認\n",
    "print \"値0\", len(result_re.query('Survived == 0'))\n",
    "print \"値1\", len(result_re.query('Survived == 1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果を出力\n",
    "output = os.path.join(output_dir, \"survived_predict.csv\")\n",
    "result_re.to_csv(output, encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf_log.predict(test_dum)\n",
    "print(confusion_matrix(gen_data.Survived,prediction))\n",
    "print(classification_report(gen_data.Survived,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗客番号と予測結果を結合\n",
    "y_re2 = pd.Series(prediction)\n",
    "# y_re = y_predict.reshape(len(y_predict),1)\n",
    "result2 = pd.concat([PassengerId, y_re2], axis=1)\n",
    "result_re2 = result2.rename(columns={0: 'Survived'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果を出力\n",
    "output = os.path.join(output_dir, \"survived_predict_2.csv\")\n",
    "result_re2.to_csv(output, encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
